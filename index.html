
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>有间博客</title>
  <meta name="author" content="CaoKun">
  <meta name="google-site-verification" content="EcCcEaqQEwdhdvpn1cAxLlCBrXOqcxJNoKACX1OAN_g" />

  
  <meta name="description" content="查看task日志 task日志目录应该是 /home/mapred/cluster-data/logs/userlogs/jobid/attemptid 2013-01-14 19:51:32,699 INFO org.apache.hadoop.mapred.ReduceTask: Task &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://caokun.me/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="有间博客" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-13231242-3']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">有间博客</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
<ul>
<iframe name="alimamaifrm" frameborder="0" marginheight="0" marginwidth="0" border="0" scrolling="no" width="572" height="69" src="http://www.taobao.com/go/act/etao/etao-promotion.php?pid=mm_35248202_3473677_11317327&g_etao=1&g_lg=1&g_w=572&g_h=69&g_txt=&g_hot=1&g_hc=3399ff" ></iframe>
</form>
</ul>
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/01/14/hadoop-too-many-fetch-failures/">关于Too Many Fetch-failures</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-01-14T21:42:00+08:00" pubdate data-updated="true">Jan 14<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/01/14/hadoop-too-many-fetch-failures/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3 id="task">查看task日志</h3>

<ul>
  <li>
    <p>task日志目录应该是 /home/mapred/cluster-data/logs/userlogs/jobid/attemptid</p>

    <pre><code>   2013-01-14 19:51:32,699 INFO org.apache.hadoop.mapred.ReduceTask: Task attempt_201211271955_3204236_r_000000_0: Failed fetch #2 from attempt_201211271955_3204236_m_009434_0
   2013-01-14 19:51:32,699 WARN org.apache.hadoop.mapred.ReduceTask: attempt_201211271955_3204236_r_000000_0 adding host hdps14035.global.alipay.com to penalty box, next contact in 8 seconds
   2013-01-14 19:51:32,699 INFO org.apache.hadoop.mapred.ReduceTask: attempt_201211271955_3204236_r_000000_0: Got 1 map-outputs from previous failures
   2013-01-14 19:51:42,703 INFO org.apache.hadoop.mapred.ReduceTask: attempt_201211271955_3204236_r_000000_0 Need another 63 map output(s) where 0 is already in progress
   2013-01-14 19:51:42,704 INFO org.apache.hadoop.mapred.ReduceTask: attempt_201211271955_3204236_r_000000_0 Scheduled 1 outputs (2 slow hosts and0 dup hosts)
   2013-01-14 19:51:42,704 INFO o
   rg.apache.hadoop.mapred.ReduceTask: Penalized(slow) Hosts: 
   2013-01-14 19:51:42,704 INFO org.apache.hadoop.mapred.ReduceTask: hdps16027.global.alipay.com Will be considered after: 18 seconds.
   2013-01-14 19:51:42,704 INFO org.apache.hadoop.mapred.ReduceTask: hdps13014.global.alipay.com Will be considered after: 0 seconds.
   2013-01-14 19:51:42,706 WARN org.apache.hadoop.mapred.ReduceTask: attempt_201211271955_3204236_r_000000_0 copy failed: attempt_201211271955_3204236_m_009434_0 from hdps14035.global.alipay.com
   2013-01-14 19:51:42,707 WARN org.apache.hadoop.mapred.ReduceTask: java.io.IOException: Server returned HTTP response code: 500 for URL: http://hdps14035.global.alipay.com:50060/mapOutput?job=job_201211271955_3204236&amp;map=attempt_201211271955_3204236_m_009434_0&amp;reduce=0
      at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)
      at sun.reflect.D
   elegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
      at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
      at sun.net.www.protocol.http.HttpURLConnection$6.run(HttpURLConnection.java:1491)
      at java.security.AccessController.doPrivileged(Native Method)
      at sun.net.www.protocol.http.HttpURLConnection.getChainedException(HttpURLConnection.java:1485)
      at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1139)
      at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getInputStream(ReduceTask.java:1427)
      at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(ReduceTask.java:1357)
      at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:1270)
      at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run
   (ReduceTask.java:1200)
   Caused by: java.io.IOException: Server returned HTTP response code: 500 for URL: http://hdps14035.global.alipay.com:50060/mapOutput?job=job_201211271955_3204236&amp;map=attempt_201211271955_3204236_m_009434_0&amp;reduce=0
      at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1436)
      ... 4 more
</code></pre>
  </li>
</ul>

<h3 id="tasktrackerout">查看 tasktracker的out日志</h3>
<pre><code>     [Unloading class sun.reflect.GeneratedMethodAccessor1]
     [Unloading class sun.reflect.GeneratedConstructorAccessor3]
     [Unloading class sun.reflect.GeneratedConstructorAccessor19]
     I am failing here
     I am failing here
     [Unloading class sun.reflect.GeneratedConstructorAccessor22]
     I am failing here
     I am failing here
     [Unloading class sun.reflect.GeneratedConstructorAccessor23]
     I am failing here
     I am failing here
     I am failing here
     I am failing here
     I am failing here
     ... ... 
</code></pre>

<h3 id="tasktrackerlog">查看tasktracker的log日志</h3>
<pre><code>      2013-01-14 20:56:02,534 INFO org.apache.hadoop.mapred.TaskTracker.clienttrace: src: 10.227.6.134:50060, dest: 10.227.7.27:48058, bytes: 0, op: MAPRED_SHUFFLE, cliID: attempt_201211271955_3213399_m_000993_0
      2013-01-14 20:56:02,547 ERROR org.mortbay.log: /mapOutput
      java.util.NoSuchElementException
      	at java.util.AbstractQueue.remove(AbstractQueue.java:90)
      	at org.apache.hadoop.mapred.IndexCache.freeIndexInformation(IndexCache.java:151)
      	at org.apache.hadoop.mapred.IndexCache.readIndexFileToCache(IndexCache.java:124)
      	at org.apache.hadoop.mapred.IndexCache.getIndexInformation(IndexCache.java:66)
      	at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:3373)
      	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
      	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
      	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)
      	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)
      	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
      	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)
      	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
      	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)
      	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
      	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
      	at org.mortbay.jetty.Server.handle(Server.java:326)
      	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)
      	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)
      	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)
      	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)
      	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)
      	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)
      	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)
</code></pre>

<h3 id="section">初步结论</h3>

<ul>
  <li>初步认为是tasktracker内部出异常了，需要重启所以的tasktracker</li>
</ul>

<h3 id="dumptasktracker">重启前先dump出一份tasktracker内存供后面分析</h3>
<p>　　　　　　jmap -dump:live,format=b,file=/tmp/tasktracker_heap.bin 19189</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/01/09/hadoop-error-list/">Hadoop Error List</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-01-09T11:59:00+08:00" pubdate data-updated="true">Jan 9<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/01/09/hadoop-error-list/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
  <li><a href="http://caokun.me/blog/2013/01/07/hadoop-hive-task-fail-to-report-status/">关于Task Failed to Report Status for 601 Seconds 错误</a></li>
  <li><a href="http://caokun.me/blog/2013/01/04/hadoop-task-unassigned/">Map Task 或 Reduce Task 一直处于UNASSIGNED状态</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/01/07/hadoop-hive-task-fail-to-report-status/">关于Task Failed to Report Status for 601 Seconds 错误</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-01-07T11:30:00+08:00" pubdate data-updated="true">Jan 7<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/01/07/hadoop-hive-task-fail-to-report-status/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3 id="section">问题现象</h3>

<p>Task attempt<em>201211271955</em>2680877<em>m</em>000004_0 failed to report status for 601 seconds. Killing!</p>

<p>出现这个错误的原因是：运行在Hadoop上的作业，默认配置下task需要在10分钟内汇报自己的进度，如果超过10分钟没有</p>

<p>汇报进度的话，那么taskTracker就会认为该task已经失败，并汇报给jobTracker,通常是因为处理一行记录超过了10分钟</p>

<h3 id="section-1">常规解决方法:</h3>

<p>首先可以自己打印log查看程序慢在哪一步，然后做针对性优化</p>

<p>另外也在适当的地方（比如map或reduce函数内部）加上reporter.progress()，定期汇报进度</p>

<p>如果你确认task汇报进度的时间间隔是要超过10分钟，可以修改mapred.task.timeout参数，默认值是600000(毫秒)，适当调大该值，设为0表示没有超时。</p>

<h3 id="section-2">排查过程</h3>
<ul>
  <li>
    <p>登录到hung住的节点机器</p>

    <pre><code>   $ps uxf | grep 201212271955_2688574  --查看到这个attemp task执行的子进程id 
   $jstack 16113 &gt; /tmp/js.log --查看这个子进程的jstack信息
   $vi /tmp/js.log --查看日志信息，看看这么多时间内都在干什么
</code></pre>
  </li>
</ul>

<p>可以查看到如下信息：</p>

<pre><code>     "main" prio=10 tid=0x000000004046a800 nid=0x3ef3 runnable [0x00000000417f7000]
      java.lang.Thread.State: RUNNABLE
           at org.apache.hadoop.io.Text.setCapacity(Text.java:240)
           at org.apache.hadoop.io.Text.append(Text.java:216)
           at org.apache.hadoop.util.LineReader.readLine(LineReader.java:141)
           at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:133)
           - locked &lt;0x00000000e5f012c0&gt; (a org.apache.hadoop.mapred.LineRecordReader)
           at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:38)
           at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:273)
           at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.doNext(CombineHiveRecordReader.java:101)
           at org.apache.hadoop.hive.ql.io.CombineHiveRecordReader.doNext(CombineHiveRecordReader.java:41)
           at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.next(HiveContextAwareRecordReader.java:108)
           at org.apache.hadoop.hive.shims.Hadoop20Shims$CombineFileRecordReader.doNextWithExceptionHandler(Hadoop20Shims.java:307)
           at org.apache.hadoop.hive.shims.Hadoop20Shims$CombineFileRecordReader.next(Hadoop20Shims.java:225)
           at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:198)
           - locked &lt;0x00000000e5f013a0&gt; (a org.apache.hadoop.mapred.MapTask$TrackedRecordReader)
           at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:183)
           - locked &lt;0x00000000e5f013a0&gt; (a org.apache.hadoop.mapred.MapTask$TrackedRecordReader)
           at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:48)
           at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:367)
           at org.apache.hadoop.mapred.MapTask.run(MapTask.java:317)
           at org.apache.hadoop.mapred.Child.main(Child.java:167)
</code></pre>

<p>从上面信息可以看到：</p>

<p>1：这是一个Hive SQL job</p>

<p>2: 在处理一行数据，这行数据非常长，然后text不断进行扩容来存储</p>

<ul>
  <li>Hive SQL 排查</li>
</ul>

<p>发现这个SQL是 select count(*) from tablename;这样的语句，而这个语句在另一台服务器上可以正常执行</p>

<p>通过select * from tablename limit 1; 发现显示的第一个字段内容是 SEQ”org.apache.hadoop.io.BytesWriteableorg.apache.hadoop.io.Text….这样的内容</p>

<p>这说明表内的数据实际是SequenceFile格式的，而将整个SEQ 文件作为了一列的一行数据进行了处理！</p>

<p>查看desc formatted tablename; 发现果然表模式定义中定义的是SimpleText存储格式的。问题就此定位到。</p>

<ul>
  <li>向社区提个BUG</li>
</ul>

<p><a href="https://issues.apache.org/jira/browse/HIVE-3867">HIVE-3867</a></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/01/04/hive-array-map-structs/">HIVE中map，array和structs使用</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-01-04T14:16:00+08:00" pubdate data-updated="true">Jan 4<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/01/04/hive-array-map-structs/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
  <li>
    <p>关于数组的操作说明：</p>

    <pre><code>   drop table if exists table2;
   create table table2 (a array&lt;string&gt;, b array&lt;string&gt;)
   ROW FORMAT DELIMITED
   FIELDS TERMINATED BY '\t'
   COLLECTION ITEMS TERMINATED BY ',';
     
   load data local inpath "../hive/examples/files/arraytest.txt"  overwrite into table table2;
     
   arraytest.txt中的数据形式为：（不同数组间用\t分割，同一数组内不同元素用逗号分割）
   b00,b01        b00,b01
   b00,b01        b00,b01
   b00,b01        b00,b01
   b00,b01        b00,b01
     
     
   hive&gt; select * from table2;
   OK
   ["b00","b01"]   ["b00","b01"]
   ["b00","b01"]   ["b00","b01"]
   ["b00","b01"]   ["b00","b01"]
   ["b00","b01"]   ["b00","b01"]
   Time taken: 0.056 seconds
     
   hive&gt; select a from table2;
   OK
   ["b00","b01"]
   ["b00","b01"]
   ["b00","b01"]
   ["b00","b01"]
   Time taken: 15.903 seconds
     
   hive&gt; select a[0] from table2;
   OK
   b00
   b00
   b00
   b00
   Time taken: 12.913 seconds
     
   hive&gt; select * from table2 where a[0] = b[0];
   OK
   ["b00","b01"]   ["b00","b01"]
   ["b00","b01"]   ["b00","b01"]
   ["b00","b01"]   ["b00","b01"]
   ["b00","b01"]   ["b00","b01"]
   Time taken: 11.803 seconds
</code></pre>
  </li>
  <li>
    <p>关于map的操作说明：</p>

    <pre><code>   drop table if exists table2;
   CREATE TABLE table2 (foo STRING , bar MAP&lt;STRING, STRING&gt;)
   ROW FORMAT DELIMITED
   FIELDS TERMINATED BY '\t'
   COLLECTION ITEMS TERMINATED BY ','
   MAP KEYS TERMINATED BY ':'
   STORED AS TEXTFILE;
     
   load data local inpath "../hive/examples/files/maptest.txt"  overwrite into table table2;
	 
   maptest.txt中的文件格式为：（不同列之间用一个tab分割，map中key和value用冒号分割，不同K/V间用逗号分割）
   a00        b0:b01,b1:b11
   a01        b1:b11,b2:b12
   a02        b2:b12,b3:b13
   a03        b3:b13,b4:b14
     
   select bar from table2;
   OK
   {"b0":"b01","b1":"b11"}
   {"b1":"b11","b2":"b12"}
   {"b2":"b12","b3":"b13"}
   {"b3":"b13","b4":"b14"}
   Time taken: 19.237 seconds
	 
   怎么根据 key来查询value呢？
   hive&gt; select bar['b1'] from table2;
   OK
   b11
   b11
   NULL
   NULL
   Time taken: 11.65 seconds
     
   查看map中的键值对个数：
   select size(bar) from table2;
   OK
   2
   2
   2
   2
   Time taken: 12.137 seconds
</code></pre>
  </li>
</ul>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/01/04/hadoop-task-unassigned/">Map Task 或 Reduce Task 一直处于UNASSIGNED状态</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-01-04T11:13:00+08:00" pubdate data-updated="true">Jan 4<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/01/04/hadoop-task-unassigned/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
  <li>
    <p>现象是map task 或 reduce task 一直处于UNASSIGNED状态</p>
  </li>
  <li>
    <p>查看taskTracker 的jstack信息
       $JAVA_HOME/bin/jps
       9056 Child
       28402 Jps 
       13347 DataNode
       13560 TaskTracker</p>

    <pre><code>   $JAVA_HOME/bin/jstack 13560 &gt; /tmp/js_tt.log 
</code></pre>
  </li>
  <li>
    <p>jstack日志中的对应信息      <br />
       “LaunchTaskWorker for attempt<em>201211271955</em>2504854<em>m</em>000001_0” daemon prio=10 tid=0x00007fe8b8854800 nid=0x336a waiting for monitor entry [0x000000004bc66000]
          java.lang.Thread.State: BLOCKED (on object monitor)
       	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:293)
       	- waiting to lock &lt;0x00000000a00fced0&gt; (a org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext)
       	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:128)
       	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:832)
       	at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:2028)
       	at org.apache.hadoop.mapred.TaskTracker$LaunchTaskWorker.run(TaskTracker.java:1995)</p>

    <pre><code>   "TaskRunner for attempt_201211271955_2504482_m_000002_0" daemon prio=10 tid=0x00007fe8af69d800 nid=0x2b86 runnable [0x000000004c16b000]
      java.lang.Thread.State: RUNNABLE
   	at java.io.UnixFileSystem.createDirectory(Native Method)
   	at java.io.File.mkdir(File.java:1157)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:56)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:72)
   	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.createPath(LocalDirAllocator.java:257)
   	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:335)
   	- locked &lt;0x00000000a00fced0&gt; (a org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext)
   	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:128)
   	at org.apache.hadoop.filecache.DistributedCache.getLocalCache(DistributedCache.java:251)
   	- locked &lt;0x00000000a0154ab8&gt; (a java.util.TreeMap)
   	at org.apache.hadoop.filecache.DistributedCache.getLocalCache(DistributedCache.java:180)
   	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:167)
</code></pre>
  </li>
  <li>
    <p>ps uxf，看子进程</p>
  </li>
</ul>

<p>hadoop 11031 0.0 0.0 59000 708 ? D Jan03 0:00 _du -sk /disk2/data</p>

<ul>
  <li>
    <p>问题原因</p>

    <p>disk2坏盘</p>
  </li>
  <li>
    <p>临时解决办法
       $HADOOP_HOME/bin/hadoop-deamon.sh stop tasktracker 
       如果这样终止不掉
       那么
       $kill -9 13560</p>
  </li>
  <li>
    <p>后期解决方案</p>

    <p>当tasktracker因为磁盘故障或者oom等导致task一直处于UNASSIGNED状态时，应该触发预测执行，防止job长期被hang住。</p>
  </li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/12/28/hive-hadoop-define-proper-reduce-num/">Hadoop和Hive中如何确定合适的reduce Task个数使得数据分发均匀</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-12-28T17:24:00+08:00" pubdate data-updated="true">Dec 28<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/12/28/hive-hadoop-define-proper-reduce-num/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3 id="hadoophash">Hadoop中计算hash值的算法</h3>
<pre><code>    package org.apache.hadoop.mapred.lib;
    import org.apache.hadoop.mapred.Partitioner;
    import org.apache.hadoop.mapred.JobConf;
    
    /** Partition keys by their {@link Object#hashCode()}. 
     */
    public class HashPartitioner&lt;K2, V2&gt; implements Partitioner&lt;K2, V2&gt; {
    
      public void configure(JobConf job) {}
      /** Use {@link Object#hashCode()} to partition. */
      public int getPartition(K2 key, V2 value,
                              int numReduceTasks) {
        return (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;
      }
    }
</code></pre>

<h3 id="hivehiveql">Hive中通过HiveQL来查看键是否分布均匀</h3>
<pre><code>	select  ( hash(card_no) &amp; 2147483647 ) % 8 as hash_code ,count(1) as cnt
	from    dwb_cbz_cs_user_grade_dd
	where   dt = '20121007'
	group by ( hash(card_no) &amp; 2147483647 ) % 8
	order by cnt  desc
	limit 10;
</code></pre>

<h3 id="reduce-task">如何确定合适的reduce task个数</h3>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/12/28/ubuntu-install-mysql/">Ubuntu Install Mysql</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-12-28T11:32:00+08:00" pubdate data-updated="true">Dec 28<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/12/28/ubuntu-install-mysql/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3 id="install-mysql">Install MySQL</h3>
<pre><code>    sudo apt-get install mysql-server 
    sudo apt-get install mysql 
    sudo apt-get install mysql-devel
    sudo apt-get install mysql-client
</code></pre>

<h3 id="start-mysql-server">Start MySQL Server</h3>
<pre><code>    service mysql start
    chkconfig --levels 235 mysql on
</code></pre>

<h3 id="config-root-user-password">Config root user password</h3>
<pre><code>    mysql&gt; use mysql;
    mysql&gt; update user set password=PASSWORD("root") where User='root';
    mysql&gt; flush privileges;
    mysql&gt; quit
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/12/28/hive-install/">Hive安装和配置</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-12-28T11:31:00+08:00" pubdate data-updated="true">Dec 28<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/12/28/hive-install/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3 id="mysql">安装MySQL</h3>
<p>本文使用MySQL作为Hive元数据存储数据库
* <a href="http://caokun.me/blog/2012/12/28/ubuntu-install-mysql/">ubuntu下如何安装MySQL</a></p>

<h3 id="hive">获取Hive软件包</h3>
<pre><code>    ~$ wget http://mirror.bit.edu.cn/apache/hive/hive-0.9.0/hive-0.9.0.tar.gz  ./
    ~$ tar -zxvf hive-0.9.0.tar.gz
    ~$ ln -s  ./hive-0.9.0  hive-current
    ~$ mkdir hive-conf 
    ~$ cp -r ./hive-current/conf/*  ./hive-conf/
</code></pre>

<h3 id="bashprofile-bashrc">修改 ～/.bash_profile或者 ～/.bashrc,增加如下内容</h3>
<pre><code>    export HADOOP_HOME=/home/zongren/hadoop-current
    export HADOOP_CONF_DIR=/home/zongren/hadoop-conf
    export HIVE_HOME=/home/zongren/hive-current
    export HIVE_CONF_DIR=/home/zongren/hive-conf
    export ddCLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib 
    export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$ANT_HOME/bin:$FORREST_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:$MVN_HOME/bin:$PATH:$HOME/bin 
</code></pre>

<h3 id="hive-1">Hive通常的配置</h3>
<p>修改$HIVE_CONF_DIR/hive-site.xml文件
          <configuration /></p>

<pre><code>      &lt;property&gt;
        &lt;name&gt;mapred.reduce.tasks&lt;/name&gt;
        &lt;value&gt;-1&lt;/value&gt;
      &lt;/property&gt;
      
      &lt;property&gt;
        &lt;name&gt;hive.exec.reducers.max&lt;/name&gt;
        &lt;value&gt;1000&lt;/value&gt;
      &lt;/property&gt;
      
      &lt;property&gt;
        &lt;name&gt;hive.metastore.local&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
      &lt;/property&gt;
      
      &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
        &lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;
      &lt;/property&gt;
      
      &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
      &lt;/property&gt;
      
      &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
        &lt;value&gt;root&lt;/value&gt;
      &lt;/property&gt;
      
      &lt;property&gt;
        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
        &lt;value&gt;root&lt;/value&gt;
      &lt;/property&gt;
      
      &lt;property&gt;
      	&lt;name&gt;hive.exec.scratchdir&lt;/name&gt;
      	&lt;value&gt;/user/${user.name}/hive-scratchdir&lt;/value&gt;
      &lt;/property&gt;
      
      &lt;property&gt;
        &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
        &lt;value&gt;/user/${user.name}/hive&lt;/value&gt;
        &lt;description&gt;location of default database for the warehouse&lt;/description&gt;
      &lt;/property&gt;
      
      &lt;property&gt;
        &lt;name&gt;hive.cli.print.current.db&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
        &lt;description&gt;Whether to include the current database in the hive prompt.&lt;/description&gt;
      &lt;/property&gt;
      
      &lt;/configuration&gt;
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/12/27/hive-touch/">Hive中的touch</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-12-27T20:07:00+08:00" pubdate data-updated="true">Dec 27<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/12/27/hive-touch/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3 id="wiki">wiki</h3>
<ul>
  <li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-AlterTableTouch">Alter Table Touch</a></li>
</ul>

<h3 id="jira">jira</h3>
<ul>
  <li><a href="https://issues.apache.org/jira/browse/HIVE-1300">HIVE-1300</a></li>
</ul>

<h3 id="section">作用</h3>
<p>读取元数据信息，然后再把元数据信息重新写入到元数据库中。</p>

<p>解决的问题场景一：
用户写了个hook来记录所有表和分区被改动的操作日志，同时有个外部脚本直接去修改了HDFS中的文件，
因为操作是在hive之外完成的，那么这个修改过程也就不会记录到操作日志中。这时这个外部脚本是可以通过调用touch命令来标记出有改动。</p>

<h3 id="section-1">使用方式</h3>
<pre><code>    ALTER TABLE tstsrc TOUCH;
    ALTER TABLE tstsrcpart TOUCH;
    ALTER TABLE tstsrcpart TOUCH PARTITION (ds='2008-04-08', hr='12');
</code></pre>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/12/26/build-blog-using-github-and-octopress/">使用GitHub和OctoPress搭建个人blog</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-12-26T20:33:00+08:00" pubdate data-updated="true">Dec 26<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/12/26/build-blog-using-github-and-octopress/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2 id="github">安装GitHub</h2>
<p>自己Google吧
##创建github工程并配置免密码服务
* 建github工程
工程名一般为username.github.com
* <a href="https://help.github.com/articles/generating-ssh-keys">配置免密码服务</a>
##安装Ruby
* 安装Ruby 1.9.3
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
<span class="line-number">2</span>
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line">  <span class="nx">sudo</span> <span class="nx">apt</span><span class="o">-</span><span class="nx">get</span> <span class="nx">install</span> <span class="nx">ruby1</span><span class="p">.</span><span class="mf">9.3</span>
</span><span class="line">  <span class="nx">sudo</span> <span class="nx">aptitude</span> <span class="nx">install</span> <span class="nx">ruby1</span><span class="p">.</span><span class="mf">9.1</span><span class="o">-</span><span class="nx">dev</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;</figure></notextile>&lt;/div&gt;
可以检查下系统的 /usr/bin下安装有多少个版本的ruby
并将默认的软链接指向到1.9.3版本
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line"><span class="o">~</span><span class="err">#</span> <span class="nx">rm</span> <span class="o">-</span><span class="nx">rf</span> <span class="o">/</span><span class="nx">usr</span><span class="o">/</span><span class="nx">bin</span><span class="o">/</span><span class="nx">ruby</span>
</span><span class="line"><span class="o">~</span><span class="err">#</span> <span class="nx">ln</span> <span class="o">-</span><span class="nx">s</span>   <span class="o">/</span><span class="nx">usr</span><span class="o">/</span><span class="nx">bin</span><span class="o">/</span><span class="nx">ruby1</span><span class="p">.</span><span class="mf">9.3</span>  <span class="o">/</span><span class="nx">usr</span><span class="o">/</span><span class="nx">bin</span><span class="o">/</span><span class="nx">ruby</span>
</span><span class="line"><span class="o">~</span><span class="err">#</span> <span class="nx">ruby</span> <span class="o">-</span><span class="nx">v</span>
</span><span class="line"><span class="nx">ruby</span> <span class="mf">1.9</span><span class="p">.</span><span class="mi">3</span><span class="nx">p0</span> <span class="p">(</span><span class="mi">2011</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="mi">30</span> <span class="nx">revision</span> <span class="mi">33570</span><span class="p">)</span> <span class="p">[</span><span class="nx">i686</span><span class="o">-</span><span class="nx">linux</span><span class="p">]</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;</figure></notextile>&lt;/div&gt;
* 安装依赖
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line">  <span class="nx">gem</span> <span class="nx">install</span> <span class="nx">bundler</span>
</span><span class="line">  <span class="nx">rbenv</span> <span class="nx">rehash</span>
</span><span class="line">  <span class="nx">bundle</span> <span class="nx">install</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;</figure></notextile>&lt;/div&gt;
##安装Octopress
* 安装默认的Octopress主题
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line">  <span class="nx">rake</span> <span class="nx">install</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;</figure></notextile>&lt;/div&gt;
* 生产部署文件
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line"><span class="nx">rake</span> <span class="nx">setup_github_pages</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;</figure></notextile>&lt;/div&gt;
* 修改CNAME文件
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
<span class="line-number">2</span>
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line"><span class="o">~</span><span class="err">/myworkspace/octopress/source$ cat CNAME </span>
</span><span class="line"><span class="nx">caokun</span><span class="p">.</span><span class="nx">me</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;</figure></notextile>&lt;/div&gt;</p>

<ul>
  <li>编译并部署
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
<span class="line-number">2</span></figure></notextile></li>
</ul>
<p>&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line"><span class="nx">rake</span> <span class="nx">generate</span>
</span><span class="line"><span class="nx">rake</span> <span class="nx">deploy</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/figure&gt;&lt;/notextile&gt;&lt;/div&gt;
如上两个命令和如下命令等价的：
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line"><span class="nx">rake</span> <span class="nx">gen_deploy</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;</figure></notextile>&lt;/div&gt;
如果需要本地调试的话可以执行如下命令:
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
<span class="line-number">2</span>
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line"><span class="nx">rake</span> <span class="nx">generate</span>
</span><span class="line"><span class="nx">rake</span> <span class="nx">preview</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;</figure></notextile>&lt;/div&gt;
然后打开浏览器访问localhost:4000就可以看到修改后的样子了
* 提交代码到Github
&lt;div class=&#8217;bogus-wrapper&#8217;&gt;<notextile><figure class="code">&lt;figcaption&gt;<span></span>&lt;/figcaption&gt;&lt;div class=&#8221;highlight&#8221;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#8221;gutter&#8221;&gt;&lt;pre class=&#8221;line-numbers&#8221;&gt;<span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#8217;code&#8217;&gt;&lt;pre&gt;<code class="javascript"><span class="line">  <span class="nx">git</span> <span class="nx">add</span> <span class="p">.</span>
</span><span class="line">  <span class="nx">git</span> <span class="nx">commit</span> <span class="o">-</span><span class="nx">m</span> <span class="s1">&#39;your message&#39;</span>
</span><span class="line">  <span class="nx">git</span> <span class="nx">push</span> <span class="nx">origin</span> <span class="nx">source</span>  <span class="c1">//需要按要求输入用户信息</span>
</span></code>&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;</figure></notextile>&lt;/div&gt;
* 预览区域<code>代码高亮</code>
* 所有选项自动记忆</p>

<h2 id="section">参考</h2>
<ul>
  <li><a href="http://octopress.org/docs/setup/">octopress setup</a> </li>
  <li><a href="http://sourceforge.net/adobe/tlf/wiki/markdown_syntax/">markdown语法说明</a></li>
</ul>

<h2 id="section-1">关于作者</h2>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="javascript"><span class="line">  <span class="kd">var</span> <span class="nx">ihubo</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="line">    <span class="nx">nickName</span>  <span class="o">:</span> <span class="s2">&quot;CaoKun&quot;</span><span class="p">,</span>
</span><span class="line">    <span class="nx">site</span> <span class="o">:</span> <span class="s2">&quot;http://caokun.me&quot;</span>
</span><span class="line">  <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Category Cloud</h1>
    <span id="tag-cloud"><a href='/blog/categories/hadoop' style='font-size: 150.0%'>hadoop(5)</a> <a href='/blog/categories/hive' style='font-size: 160.0%'>hive(6)</a> <a href='/blog/categories/linux' style='font-size: 120.0%'>linux(2)</a> <a href='/blog/categories/octopress' style='font-size: 110.0%'>octopress(1)</a> </span>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/01/14/hadoop-too-many-fetch-failures/">关于Too Many fetch-failures</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/01/09/hadoop-error-list/">Hadoop Error List</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/01/07/hadoop-hive-task-fail-to-report-status/">关于Task failed to report status for 601 seconds 错误</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/01/04/hive-array-map-structs/">HIVE中map，array和structs使用</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/01/04/hadoop-task-unassigned/">map task 或 reduce task 一直处于UNASSIGNED状态</a>
      </li>
    
  </ul>
</section>

<section class="googleplus googleplus-hidden">
  <h1>
    <a href="https://plus.google.com/107717946194558697634?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      Google+
    </a>
  </h1>
</section>



<section>
  <h1>alimama</h1>
<script type="text/javascript"> 
alimama_pid="mm_35248202_3473677_11317258"; 
alimama_width=950; 
alimama_height=90; 
</script> 
<script src="http://a.alimama.cn/inf.js" type="text/javascript"> 
</script>
</section>

<iframe name="alimamaifrm" frameborder="0" marginheight="0" marginwidth="0" border="0" scrolling="no" width="300" height="170" src="http://www.taobao.com/go/app/tbk_app/chongzhi_300_170.php?pid=mm_35248202_3473677_11317350&page=chongzhi_300_170.php&size_w=300&size_h=170&stru_phone=1&stru_game=1&stru_travel=1" ></iframe>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - CaoKun -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'caokunme';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>





  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>







</body>
</html>
