<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: hadoop | 有间博客]]></title>
  <link href="http://caokun.me/blog/categories/hadoop/atom.xml" rel="self"/>
  <link href="http://caokun.me/"/>
  <updated>2013-01-04T14:17:44+08:00</updated>
  <id>http://caokun.me/</id>
  <author>
    <name><![CDATA[CaoKun]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[map task 或 reduce task 一直处于UNASSIGNED状态]]></title>
    <link href="http://caokun.me/blog/2013/01/04/hadoop-task-unassigned/"/>
    <updated>2013-01-04T11:13:00+08:00</updated>
    <id>http://caokun.me/blog/2013/01/04/hadoop-task-unassigned</id>
    <content type="html"><![CDATA[<ul>
  <li>
    <p>现象是map task 或 reduce task 一直处于UNASSIGNED状态</p>
  </li>
  <li>
    <p>查看taskTracker 的jstack信息
       $JAVA_HOME/bin/jps
       9056 Child
       28402 Jps 
       13347 DataNode
       13560 TaskTracker</p>

    <pre><code>   $JAVA_HOME/bin/jstack 13560 &gt; /tmp/js_tt.log 
</code></pre>
  </li>
  <li>
    <p>jstack日志中的对应信息      <br />
       “LaunchTaskWorker for attempt<em>201211271955</em>2504854<em>m</em>000001_0” daemon prio=10 tid=0x00007fe8b8854800 nid=0x336a waiting for monitor entry [0x000000004bc66000]
          java.lang.Thread.State: BLOCKED (on object monitor)
       	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:293)
       	- waiting to lock &lt;0x00000000a00fced0&gt; (a org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext)
       	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:128)
       	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:832)
       	at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:2028)
       	at org.apache.hadoop.mapred.TaskTracker$LaunchTaskWorker.run(TaskTracker.java:1995)</p>

    <pre><code>   "TaskRunner for attempt_201211271955_2504482_m_000002_0" daemon prio=10 tid=0x00007fe8af69d800 nid=0x2b86 runnable [0x000000004c16b000]
      java.lang.Thread.State: RUNNABLE
   	at java.io.UnixFileSystem.createDirectory(Native Method)
   	at java.io.File.mkdir(File.java:1157)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:56)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.mkdirsWithExistsCheck(DiskChecker.java:66)
   	at org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:72)
   	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.createPath(LocalDirAllocator.java:257)
   	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:335)
   	- locked &lt;0x00000000a00fced0&gt; (a org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext)
   	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:128)
   	at org.apache.hadoop.filecache.DistributedCache.getLocalCache(DistributedCache.java:251)
   	- locked &lt;0x00000000a0154ab8&gt; (a java.util.TreeMap)
   	at org.apache.hadoop.filecache.DistributedCache.getLocalCache(DistributedCache.java:180)
   	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:167)
</code></pre>
  </li>
  <li>
    <p>ps uxf，看子进程</p>
  </li>
</ul>

<p>hadoop 11031 0.0 0.0 59000 708 ? D Jan03 0:00 _du -sk /disk2/data</p>

<ul>
  <li>
    <p>问题原因</p>

    <p>disk2坏盘</p>
  </li>
  <li>
    <p>临时解决办法
       $HADOOP_HOME/bin/hadoop-deamon.sh stop tasktracker 
       如果这样终止不掉
       那么
       $kill -9 13560</p>
  </li>
  <li>
    <p>后期解决方案</p>

    <p>当tasktracker因为磁盘故障或者oom等导致task一直处于UNASSIGNED状态时，应该触发预测执行，防止job长期被hang住。</p>
  </li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop和Hive中如何确定合适的reduce task个数使得数据分发均匀]]></title>
    <link href="http://caokun.me/blog/2012/12/28/hive-hadoop-define-proper-reduce-num/"/>
    <updated>2012-12-28T17:24:00+08:00</updated>
    <id>http://caokun.me/blog/2012/12/28/hive-hadoop-define-proper-reduce-num</id>
    <content type="html"><![CDATA[<h3 id="hadoophash">Hadoop中计算hash值的算法</h3>
<pre><code>    package org.apache.hadoop.mapred.lib;
    import org.apache.hadoop.mapred.Partitioner;
    import org.apache.hadoop.mapred.JobConf;
    
    /** Partition keys by their {@link Object#hashCode()}. 
     */
    public class HashPartitioner&lt;K2, V2&gt; implements Partitioner&lt;K2, V2&gt; {
    
      public void configure(JobConf job) {}
      /** Use {@link Object#hashCode()} to partition. */
      public int getPartition(K2 key, V2 value,
                              int numReduceTasks) {
        return (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;
      }
    }
</code></pre>

<h3 id="hivehiveql">Hive中通过HiveQL来查看键是否分布均匀</h3>
<pre><code>	select  ( hash(card_no) &amp; 2147483647 ) % 8 as hash_code ,count(1) as cnt
	from    dwb_cbz_cs_user_grade_dd
	where   dt = '20121007'
	group by ( hash(card_no) &amp; 2147483647 ) % 8
	order by cnt  desc
	limit 10;
</code></pre>

<h3 id="reduce-task">如何确定合适的reduce task个数</h3>

]]></content>
  </entry>
  
</feed>
